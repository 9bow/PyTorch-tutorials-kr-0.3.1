{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nPyTorch: \uc81c\uc5b4 \ud750\ub984(Control Flow) + \uac00\uc911\uce58 \uacf5\uc720(Weight Sharing)\n---------------------------------------------------------------\n\nPyTorch \ub3d9\uc801 \uadf8\ub798\ud504\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\uae30 \uc704\ud574, \ub9e4\uc6b0 \uc774\uc0c1\ud55c \ubaa8\ub378\uc744 \uad6c\ud604\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4:\n\uac01\uac01\uc758 \uc21c\uc804\ud30c \ub2e8\uacc4\uc5d0\uc11c \ub9ce\uc740 \uc740\ub2c9 \uacc4\uce35\uc744 \uac16\ub294 \uc644\uc804\ud788 \uc5f0\uacb0(Fully-connected)\ub41c ReLU\n\uc2e0\uacbd\ub9dd\uc774 \ubb34\uc791\uc704\ub85c 1 ~ 4 \uc0ac\uc774\uc758 \uc22b\uc790\ub97c \uc120\ud0dd\ud558\uace0, \ub3d9\uc77c\ud55c \uac00\uc911\uce58\ub97c \uc5ec\ub7ec \ubc88 \uc7ac\uc0ac\uc6a9\ud558\uc5ec\n\uac00\uc7a5 \uc548\ucabd(Innermost)\uc5d0 \uc788\ub294 \uc740\ub2c9 \uacc4\uce35\ub4e4\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import random\nimport torch\nfrom torch.autograd import Variable\n\n\nclass DynamicNet(torch.nn.Module):\n    def __init__(self, D_in, H, D_out):\n        \"\"\"\n        \uc0dd\uc131\uc790\uc5d0\uc11c\ub294 \uc21c\uc804\ud30c \ub2e8\uacc4\uc5d0\uc11c \uc0ac\uc6a9\ud560 3\uac1c\uc758 nn.Linear \uac1c\uccb4(Instance)\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.\n        \"\"\"\n        super(DynamicNet, self).__init__()\n        self.input_linear = torch.nn.Linear(D_in, H)\n        self.middle_linear = torch.nn.Linear(H, H)\n        self.output_linear = torch.nn.Linear(H, D_out)\n\n    def forward(self, x):\n        \"\"\"\n        \ubaa8\ub378\uc758 \uc21c\uc804\ud30c \ub2e8\uacc4\uc5d0\uc11c, \ubb34\uc791\uc704\ub85c 0, 1, 2 \ub610\ub294 3 \uc911\uc5d0 \ud558\ub098\ub97c \uc120\ud0dd\ud558\uace0\n        \uc740\ub2c9 \uacc4\uce35 \ud45c\ud604(representation)\uc744 \uacc4\uc0b0\ud558\uae30 \uc704\ud574 \uc5ec\ub7ec\ubc88 \uc0ac\uc6a9\ud55c middle_linear\n        \ubaa8\ub4c8\uc744 \uc7ac\uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n        \uac01 \uc21c\uc804\ud30c \ub2e8\uacc4\uc5d0\uc11c \ub3d9\uc801 \uc5f0\uc0b0 \uadf8\ub798\ud504\ub97c \uad6c\uc131\ud558\uae30 \ub54c\ubb38\uc5d0, \ubaa8\ub378\uc758 \uc21c\uc804\ud30c \ub2e8\uacc4\ub97c\n        \uc815\uc758\ud560 \ub54c \ubc18\ubcf5\ubb38\uc774\ub098 \uc870\uac74\ubb38\uacfc \uac19\uc774 \uc77c\ubc18\uc801\uc778 Python \uc81c\uc5b4 \ud750\ub984 \uc5f0\uc0b0\uc790\ub97c \uc0ac\uc6a9\ud560\n        \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n        \uc5ec\uae30\uc5d0\uc11c \uc5f0\uc0b0 \uadf8\ub798\ud504\ub97c \uc815\uc758\ud560 \ub54c \ub3d9\uc77c\ud55c \ubaa8\ub4c8\uc744 \uc5ec\ub7ec\ubc88 \uc7ac\uc0ac\uc6a9\ud558\ub294 \uac83\uc774\n        \uc644\ubcbd\ud558\uac8c \uc548\uc804\ud558\ub2e4\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\uac83\uc774 \uac01 \ubaa8\ub4c8\uc744 \ud55c \ubc88\ub9cc \uc0ac\uc6a9\ud558\ub294\n        Lua Torch\ubcf4\ub2e4 \ud06c\uac8c \uac1c\uc120\ub41c \ubd80\ubd84\uc785\ub2c8\ub2e4.\n        \"\"\"\n        h_relu = self.input_linear(x).clamp(min=0)\n        for _ in range(random.randint(0, 3)):\n            h_relu = self.middle_linear(h_relu).clamp(min=0)\n        y_pred = self.output_linear(h_relu)\n        return y_pred\n\n\n# N\uc740 \ubc30\uce58 \ud06c\uae30\uc774\uba70, D_in\uc740 \uc785\ub825\uc758 \ucc28\uc6d0\uc785\ub2c8\ub2e4;\n# H\ub294 \uc740\ub2c9 \uacc4\uce35\uc758 \ucc28\uc6d0\uc774\uba70, D_out\uc740 \ucd9c\ub825 \ucc28\uc6d0\uc785\ub2c8\ub2e4:\nN, D_in, H, D_out = 64, 1000, 100, 10\n\n# \uc785\ub825\uacfc \ucd9c\ub825\uc744 \uc800\uc7a5\ud558\uae30 \uc704\ud574 \ubb34\uc791\uc704 \uac12\uc744 \uac16\ub294 Tensor\ub97c \uc0dd\uc131\ud558\uace0, Variable\ub85c\n# \uac10\uc309\ub2c8\ub2e4.\nx = Variable(torch.randn(N, D_in))\ny = Variable(torch.randn(N, D_out), requires_grad=False)\n\n# \uc55e\uc5d0\uc11c \uc815\uc758\ud55c \ud074\ub798\uc2a4\ub97c \uc0dd\uc131(Instantiating)\ud574\uc11c \ubaa8\ub378\uc744 \uad6c\uc131\ud569\ub2c8\ub2e4.\nmodel = DynamicNet(D_in, H, D_out)\n\n# \uc190\uc2e4\ud568\uc218\uc640 Optimizer\ub97c \ub9cc\ub4ed\ub2c8\ub2e4. \uc774 \uc774\uc0c1\ud55c \ubaa8\ub378\uc744 \uc21c\uc218\ud55c \ud655\ub960\uc801 \uacbd\uc0ac \ud558\uac15\ubc95\n# (Stochastic Gradient Decent)\uc73c\ub85c \ud559\uc2b5\ud558\ub294 \uac83\uc740 \uc5b4\ub824\uc6b0\ubbc0\ub85c, momentum\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\ncriterion = torch.nn.MSELoss(size_average=False)\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\nfor t in range(500):\n    # \uc21c\uc804\ud30c \ub2e8\uacc4: \ubaa8\ub378\uc5d0 x\ub97c \uc804\ub2ec\ud558\uc5ec \uc608\uc0c1\ud558\ub294 y \uac12\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n    y_pred = model(x)\n\n    # \uc190\uc2e4\uc744 \uacc4\uc0b0\ud558\uace0 \ucd9c\ub825\ud569\ub2c8\ub2e4.\n    loss = criterion(y_pred, y)\n    print(t, loss.data[0])\n\n    # \ubcc0\ud654\ub3c4\ub97c 0\uc73c\ub85c \ub9cc\ub4e4\uace0, \uc5ed\uc804\ud30c \ub2e8\uacc4\ub97c \uc218\ud589\ud558\uace0, \uac00\uc911\uce58\ub97c \uac31\uc2e0\ud569\ub2c8\ub2e4.\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}