{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\ubd84\ub958\uae30(Classifier) \ud559\uc2b5\ud558\uae30\n===========================\n\n\uc9c0\uae08\uae4c\uc9c0 \uc5b4\ub5bb\uac8c \uc2e0\uacbd\ub9dd\uc744 \uc815\uc758\ud558\uace0, \uc190\uc2e4\uc744 \uacc4\uc0b0\ud558\uba70 \ub610 \uac00\uc911\uce58\ub97c \uac31\uc2e0\ud558\ub294\uc9c0\uc5d0\n\ub300\ud574\uc11c \ubc30\uc6e0\uc2b5\ub2c8\ub2e4.\n\n\uc774\uc81c \uc544\ub9c8\ub3c4 \uc774\ub7f0 \uc0dd\uac01\uc744 \ud558\uace0 \uacc4\uc2e4\ud150\ub370\uc694,\n\n\ub370\uc774\ud130\ub294 \uc5b4\ub5bb\uac8c \ud558\ub098\uc694?\n------------------------\n\n\uc77c\ubc18\uc801\uc73c\ub85c \uc774\ubbf8\uc9c0\ub098 \ud14d\uc2a4\ud2b8, \uc624\ub514\uc624\ub098 \ube44\ub514\uc624 \ub370\uc774\ud130\ub97c \ub2e4\ub8f0\ud150\ub370\uc694, \uc774\ub7ec\ud55c \ub370\uc774\ud130\ub294\n\ud45c\uc900 Python \ud328\ud0a4\uc9c0\ub97c \uc0ac\uc6a9\ud558\uc5ec \ubd88\ub7ec\uc628 \ud6c4 NumPy \ubc30\uc5f4\ub85c \ubcc0\ud658\ud558\uba74 \ub429\ub2c8\ub2e4.\n\uadf8\ub9ac\uace0 \uadf8 \ubc30\uc5f4\uc744 ``torch.*Tensor`` \ub85c \ubcc0\ud658\ud558\uba74 \ub429\ub2c8\ub2e4.\n\n-  \uc774\ubbf8\uc9c0\ub294 Pillow\ub098 OpenCV \uac19\uc740 \ud328\ud0a4\uc9c0\uac00 \uc720\uc6a9\ud569\ub2c8\ub2e4.\n-  \uc624\ub514\uc624\ub97c \ucc98\ub9ac\ud560 \ub54c\ub294 SciPy\uc640 LibROSA\uac00 \uc720\uc6a9\ud558\uace0\uc694.\n-  \ud14d\uc2a4\ud2b8\uc758 \uacbd\uc6b0\uc5d0\ub294 \uadf8\ub0e5 Python\uc774\ub098 Cython\uc758 \uac83\ub4e4\uc744 \uc0ac\uc6a9\ud558\uac70\ub098, NLTK\ub098 SpaCy\ub3c4\n   \uc88b\uc2b5\ub2c8\ub2e4.\n\n\ud2b9\ubcc4\ud788 \uc601\uc0c1 \ubd84\uc57c\ub97c \uc704\ud574\uc11c\ub294 ``torchvision`` \uc774\ub77c\ub294 \ud328\ud0a4\uc9c0\ub97c \ub9cc\ub4e4\uc5b4\ub450\uc5c8\ub294\ub370\uc694,\n\uc5ec\uae30\uc5d0\ub294 Imagenet\uc774\ub098 CIFAR10, MNIST \ub4f1\uacfc \uac19\uc740 \uc77c\ubc18\uc801\uc73c\ub85c \uc0ac\uc6a9\ud558\ub294 \ub370\uc774\ud130\uc14b\uc744\n\ubd88\ub7ec\uc624\ub294 \ud568\uc218\ub4e4(data loaders)\uc774\ub098, image, viz., ``torchvision.datasets`` \uc640\n``torch.utils.data.DataLoader`` \ub370\uc774\ud130 \ubcc0\ud658\uae30\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc774\ub7ec\ud55c \uae30\ub2a5\uc740 \uc5c4\uccad\ub098\uac8c \ud3b8\ub9ac\ud558\uba70, \ub9e4\ubc88 \uc720\uc0ac\ud55c \ucf54\ub4dc(boilerplate code)\ub97c \ubc18\ubcf5\ud574\uc11c\n\uc791\uc131\ud558\ub294 \uac83\uc744 \ud53c\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 CIFAR10 \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud560 \ud150\ub370\uc694, \uc5ec\uae30\uc5d0\ub294 \ub2e4\uc74c\uacfc \uac19\uc740 \ubd84\ub958\ub4e4\uc774\n\uc788\uc2b5\ub2c8\ub2e4: '\ube44\ud589\uae30(airplane)', '\uc790\ub3d9\ucc28(automobile)', '\uc0c8(bird)', '\uace0\uc591\uc774(cat)',\n'\uc0ac\uc2b4(deer)', '\uac1c(dog)', '\uac1c\uad6c\ub9ac(frog)', '\ub9d0(horse)', '\ubc30(ship)', '\ud2b8\ub7ed(truck)'.\n\uadf8\ub9ac\uace0 CIFAR10\uc5d0 \ud3ec\ud568\ub41c \uc774\ubbf8\uc9c0\uc758 \ud06c\uae30\ub294 3x32x32\uc778\ub370\uc694, \uc774\ub294 32x32 \ud53d\uc140 \ud06c\uae30\uc758 \uc774\ubbf8\uc9c0\uac00\n3\uac1c \ucc44\ub110(channel)\ub85c \uc774\ub904\uc838 \uc788\ub2e4\ub294 \ub73b\uc785\ub2c8\ub2e4.\n\n.. figure:: /_static/img/cifar10.png\n   :alt: cifar10\n\n   cifar10\n\n\n\uc774\ubbf8\uc9c0 \ubd84\ub958\uae30 \ud559\uc2b5\ud558\uae30\n----------------------------\n\n\ub2e4\uc74c\uc758 \ub2e8\uacc4\ub85c \uc9c4\ud589\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4:\n\n1. CIFAR10\uc758 \ud559\uc2b5\uc6a9 / \uc2dc\ud5d8(test)\uc6a9 \ub370\uc774\ud130\uc14b\uc744 ``torchvision`` \uc744 \uc0ac\uc6a9\ud558\uc5ec\n   \ubd88\ub7ec\uc624\uace0, \uc815\uaddc\ud654(nomarlizing)\ud569\ub2c8\ub2e4.\n2. \ud569\uc131\uacf1 \uc2e0\uacbd\ub9dd(Convolution Neural Network)\uc744 \uc815\uc758\ud569\ub2c8\ub2e4.\n3. \uc190\uc2e4 \ud568\uc218\ub97c \uc815\uc758\ud569\ub2c8\ub2e4.\n4. \ud559\uc2b5\uc6a9 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc2e0\uacbd\ub9dd\uc744 \ud559\uc2b5\ud569\ub2c8\ub2e4.\n5. \uc2dc\ud5d8\uc6a9 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc2e0\uacbd\ub9dd\uc744 \uac80\uc0ac\ud569\ub2c8\ub2e4.\n\n1. CIFAR10\ub97c \ubd88\ub7ec\uc624\uace0 \uc815\uaddc\ud654\ud558\uae30\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``torchvision`` \uc744 \uc0ac\uc6a9\ud558\uba74 \ub9e4\uc6b0 \uc27d\uac8c CIFAR10 \ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc62c \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torchvision\nimport torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "torchvision \ub370\uc774\ud130\uc14b\uc758 \ucd9c\ub825(output)\uc740 [0, 1] \ubc94\uc704\ub97c \uac16\ub294 PILImage \uc774\ubbf8\uc9c0\uc785\ub2c8\ub2e4.\n\uc774\ub97c [-1, 1]\uc758 \ubc94\uc704\ub85c \uc815\uaddc\ud654\ub41c Tensor\ub85c \ubcc0\ud658\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=4,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc7ac\ubbf8\uc0bc\uc544 \ud559\uc2b5\uc6a9 \uc774\ubbf8\uc9c0 \uba87 \uac1c\ub97c \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\n\n# \uc774\ubbf8\uc9c0\ub97c \ubcf4\uc5ec\uc8fc\uae30 \uc704\ud55c \ud568\uc218\n\n\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\n\n# \ud559\uc2b5\uc6a9 \uc774\ubbf8\uc9c0\ub97c \ubb34\uc791\uc704\ub85c \uac00\uc838\uc624\uae30\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\n\n# \uc774\ubbf8\uc9c0 \ubcf4\uc5ec\uc8fc\uae30\nimshow(torchvision.utils.make_grid(images))\n# \uc815\ub2f5(label) \ucd9c\ub825\nprint(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. \ud569\uc131\uacf1 \uc2e0\uacbd\ub9dd(Convolution Neural Network) \uc815\uc758\ud558\uae30\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\uc774\uc804\uc5d0 \ubc30\uc6e0\ub358 \uc2e0\uacbd\ub9dd \uc139\uc158\uc5d0\uc11c \uc2e0\uacbd\ub9dd\uc744 \ubcf5\uc0ac\ud558\uace0, (\uae30\uc874\uc5d0 1\ucc44\ub110 \uc774\ubbf8\uc9c0\ub9cc \ucc98\ub9ac\ud558\ub358\n\uac83 \ub300\uc2e0) 3\ucc44\ub110 \uc774\ubbf8\uc9c0\ub97c \ucc98\ub9ac\ud560 \uc218 \uc788\ub3c4\ub85d \uc218\uc815\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\nnet = Net()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. \uc190\uc2e4 \ud568\uc218\uc640 Optimizer \uc815\uc758\ud558\uae30\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\uc774\uc81c, \ubd84\ub958\uc5d0 \ub300\ud55c \uad50\ucc28 \uc5d4\ud2b8\ub85c\ud53c \uc190\uc2e4(Cross-Entropy loss)\uacfc momentum\uc744 \uac16\ub294\nSGD\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. \uc2e0\uacbd\ub9dd \ud559\uc2b5\ud558\uae30\n^^^^^^^^^^^^^^^^^^^^\n\n\uc774\uc81c\ubd80\ud130 \ud765\ubbf8\ub85c\uc6b0\uc2e4 \uac81\ub2c8\ub2e4.\n\ub370\uc774\ud130\ub97c \ubc18\ubcf5\ud574\uc11c \uc2e0\uacbd\ub9dd\uc5d0 \uc785\ub825\uc73c\ub85c \uc81c\uacf5\ud558\uace0, \ucd5c\uc801\ud654(Optimize)\ub9cc \ud558\uba74 \ub429\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for epoch in range(2):  # \ub370\uc774\ud130\uc14b\uc744 \uc218\ucc28\ub840 \ubc18\ubcf5\ud569\ub2c8\ub2e4.\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # \uc785\ub825\uc744 \ubc1b\uc740 \ud6c4,\n        inputs, labels = data\n\n        # Variable\ub85c \uac10\uc2f8\uace0\n        inputs, labels = Variable(inputs), Variable(labels)\n\n        # \ubcc0\ud654\ub3c4 \ub9e4\uac1c\ubcc0\uc218\ub97c 0\uc73c\ub85c \ub9cc\ub4e0 \ud6c4\n        optimizer.zero_grad()\n\n        # \ud559\uc2b5 + \uc5ed\uc804\ud30c + \ucd5c\uc801\ud654\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # \ud1b5\uacc4 \ucd9c\ub825\n        running_loss += loss.data[0]\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 2000))\n            running_loss = 0.0\n\nprint('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. \uc2dc\ud5d8\uc6a9 \ub370\uc774\ud130\ub85c \uc2e0\uacbd\ub9dd \uac80\uc0ac\ud558\uae30\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\ud559\uc2b5\uc6a9 \ub370\uc774\ud130\uc14b\uc744 2\ud68c \ubc18\ubcf5\ud558\uc5ec \uc2e0\uacbd\ub9dd\uc744 \ud559\uc2b5\uc2dc\ucf30\ub294\ub370\uc694, \uc2e0\uacbd\ub9dd\uc774 \uc804\ud600 \ubc30\uc6b4\uac8c\n\uc5c6\uc744\uc9c0\ub3c4 \ubaa8\ub974\ub2c8 \ud655\uc778\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n\uc2e0\uacbd\ub9dd\uc774 \uc608\uce21\ud55c \uc815\ub2f5\uacfc \uc9c4\uc9dc \uc815\ub2f5(Ground-truth)\uc744 \ube44\uad50\ud558\ub294 \ubc29\uc2dd\uc73c\ub85c \ud655\uc778\ud560\ud150\ub370\uc694,\n\uc608\uce21\uc774 \ub9de\ub2e4\uba74 \uc0d8\ud50c\uc744 '\ub9de\uc740 \uc815\ub2f5(Correct predictions)'\uc5d0 \ub123\uaca0\uc2b5\ub2c8\ub2e4.\n\n\uba3c\uc800 \uc2dc\ud5d8\uc6a9 \ub370\uc774\ud130\ub97c \uc880 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataiter = iter(testloader)\nimages, labels = dataiter.next()\n\n# \uc774\ubbf8\uc9c0 \ucd9c\ub825\nimshow(torchvision.utils.make_grid(images))\nprint('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc88b\uc2b5\ub2c8\ub2e4, \uc774\uc81c \uc2e0\uacbd\ub9dd\uc774 \uc5b4\ub5bb\uac8c \uc608\uce21\ud588\ub294\uc9c0\ub97c \ubcf4\uc8e0:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "outputs = net(Variable(images))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ucd9c\ub825\uc740 10\uac1c \ubd84\ub958 \uac01\uac01\uc5d0 \ub300\ud55c \uac12\uc73c\ub85c \ub098\ud0c0\ub0a9\ub2c8\ub2e4. \uc5b4\ub5a4 \ubd84\ub958\uc5d0 \ub300\ud574\uc11c \ub354 \ub192\uc740 \uac12\uc774\n\ub098\ud0c0\ub09c\ub2e4\ub294 \uac83\uc740, \uc2e0\uacbd\ub9dd\uc774 \uadf8 \uc774\ubbf8\uc9c0\uac00 \ub354 \ud574\ub2f9 \ubd84\ub958\uc5d0 \uac00\uae5d\ub2e4\uace0 \uc0dd\uac01\ud55c\ub2e4\ub294 \uac83\uc785\ub2c8\ub2e4.\n\ub530\ub77c\uc11c, \uac00\uc7a5 \ub192\uc740 \uac12\uc744 \uac16\ub294 \uc778\ub371\uc2a4(index)\ub97c \ubf51\uc544\ubcf4\uaca0\uc2b5\ub2c8\ub2e4:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_, predicted = torch.max(outputs.data, 1)\n\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n                              for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uacb0\uacfc\uac00 \uad1c\ucc2e\uc544\ubcf4\uc774\ub124\uc694.\n\n\uadf8\ub7fc \uc804\uccb4 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud574\uc11c\ub294 \uc5b4\ub5bb\uac8c \ub3d9\uc791\ud558\ub294\uc9c0 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "correct = 0\ntotal = 0\nfor data in testloader:\n    images, labels = data\n    outputs = net(Variable(images))\n    _, predicted = torch.max(outputs.data, 1)\n    total += labels.size(0)\n    correct += (predicted == labels).sum()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\n    100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(10\uac00\uc9c0 \ubd84\ub958\uc5d0\uc11c \ubb34\uc791\uc704\ub85c) \ucc0d\uc5c8\uc744 \ub54c\uc758 \uc815\ud655\ub3c4\uc778 10% \ubcf4\ub2e4\ub294 \ub098\uc544\ubcf4\uc785\ub2c8\ub2e4.\n\uc2e0\uacbd\ub9dd\uc774 \ubb54\uac00 \ubc30\uc6b0\uae34 \ud55c \uac83 \uac19\ub124\uc694.\n\n\uadf8\ub7fc \uc5b4\ub5a4 \uac83\ub4e4\uc744 \ub354 \uc798 \ubd84\ub958\ud558\uace0, \uc5b4\ub5a4 \uac83\ub4e4\uc744 \ub354 \ubabb\ud588\ub294\uc9c0 \uc54c\uc544\ubcf4\uaca0\uc2b5\ub2c8\ub2e4:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\nfor data in testloader:\n    images, labels = data\n    outputs = net(Variable(images))\n    _, predicted = torch.max(outputs.data, 1)\n    c = (predicted == labels).squeeze()\n    for i in range(4):\n        label = labels[i]\n        class_correct[label] += c[i]\n        class_total[label] += 1\n\n\nfor i in range(10):\n    print('Accuracy of %5s : %2d %%' % (\n        classes[i], 100 * class_correct[i] / class_total[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc790, \uc774\uc81c \ub2e4\uc74c\uc740 \ubb58\uae4c\uc694?\n\n\uc774\ub7ec\ud55c \uc2e0\uacbd\ub9dd\ub4e4\uc744 GPU\uc5d0\uc11c \uc2e4\ud589\ud55c\ub2e4\uba74 \uc5b4\ub5a8\uae4c\uc694?\n\nGPU\uc5d0\uc11c \ud559\uc2b5\ud558\uae30\n----------------\nTensor\ub97c GPU\ub85c \uc62e\uacbc\ub358 \uac83\ucc98\ub7fc, \uc2e0\uacbd\ub9dd\uc744 GPU\ub85c \uc62e\uae38 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\uc774\ub807\uac8c \ud558\uba74 \ubaa8\ub4e0 \ubaa8\ub4c8\uc5d0 \ub300\ud574\uc11c \uc7ac\uadc0\uc801\uc73c\ub85c \ucc98\ub9ac\ud558\uba70 \ub9e4\uac1c\ubcc0\uc218\uc640 \ubc84\ud37c\ub4e4\uc744 CUDA\ntensor\ub85c \ubcc0\ud658\ud558\uac8c \ub429\ub2c8\ub2e4:\n\n.. code:: python\n\n    net.cuda()\n\n\n\ubaa8\ub4e0 \ub2e8\uacc4\uc5d0\uc11c \uc785\ub825(input)\uacfc \uc815\ub2f5(target)\ub3c4 GPU\ub85c \ubcf4\ub0b4\uc57c \ud55c\ub2e4\ub294 \uac83\ub3c4 \uae30\uc5b5\ud558\uc154\uc57c\n\ud569\ub2c8\ub2e4:\n\n::\n\n        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n\nCPU\uc640 \ube44\uad50\ud588\uc744 \ub54c \uc5b4\ub9c8\uc5b4\ub9c8\ud55c \uc18d\ub3c4 \ucc28\uc774\uac00 \ub098\uc9c0 \uc54a\ub294 \uac83\uc740 \uc65c \uadf8\ub7f4\uae4c\uc694?\n\uadf8 \uc774\uc720\ub294 \ubc14\ub85c \uc2e0\uacbd\ub9dd\uc774 \ub108\ubb34 \uc791\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.\n\n**Exercise:** \uc2e0\uacbd\ub9dd\uc758 \ud06c\uae30\ub97c \ud0a4\uc6e0\uc744 \ub54c \uc5bc\ub9c8\ub098 \ube68\ub77c\uc9c0\ub294\uc9c0 \ud655\uc778\ud574\ubcf4\uc138\uc694.\n(\uccab\ubc88\uc9f8 ``nn.Conv2d`` \uc758 2\ubc88\uc9f8 \ub9e4\uac1c\ubcc0\uc218\uc640 \ub450\ubc88\uc9f8 ``nn.Conv2d`` \uc758 1\ubc88\uc9f8\n\ub9e4\uac1c\ubcc0\uc218\ub294 \uac19\uc544\uc57c \ud569\ub2c8\ub2e4.)\n\n**\ubaa9\ud45c\ub97c \ub2ec\uc131\ud588\uc2b5\ub2c8\ub2e4**:\n\n- \ub192\uc740 \uc218\uc900\uc5d0\uc11c PyTorch\uc758 Tensor library\uc640 \uc2e0\uacbd\ub9dd\ub97c \uc774\ud574\ud569\ub2c8\ub2e4.\n- \uc774\ubbf8\uc9c0\ub97c \ubd84\ub958\ud558\ub294 \uc791\uc740 \uc2e0\uacbd\ub9dd\uc744 \ud559\uc2b5\uc2dc\ud0b5\ub2c8\ub2e4.\n\n\uc5ec\ub7ec\uac1c\uc758 GPU\uc5d0\uc11c \ud559\uc2b5\ud558\uae30\n-------------------------\n\ubaa8\ub4e0 GPU\ub97c \ud65c\uc6a9\ud574\uc11c \ub354\uc6b1 \ub354 \uc18d\ub3c4\ub97c \uc62c\ub9ac\uace0 \uc2f6\ub2e4\uba74, :doc:`data_parallel_tutorial` \uc744 \ucc38\uace0\ud558\uc138\uc694.\n\n\uc774\uc81c \ubb58 \ud574\ubcfc\uae4c\uc694?\n-------------------\n\n-  :doc:`Train neural nets to play video games </intermediate/reinforcement_q_learning>`\n-  `Train a state-of-the-art ResNet network on imagenet`_\n-  `Train a face generator using Generative Adversarial Networks`_\n-  `Train a word-level language model using Recurrent LSTM networks`_\n-  `\ub2e4\ub978 \uc608\uc81c\ub4e4 \ucc38\uace0\ud558\uae30`_\n-  `\ub354 \ub9ce\uc740 \ud29c\ud1a0\ub9ac\uc5bc \ubcf4\uae30`_\n-  `\ud3ec\ub7fc\uc5d0\uc11c PyTorch\uc5d0 \ub300\ud574 \uc598\uae30\ud558\uae30`_\n-  `Slack\uc5d0\uc11c \ub2e4\ub978 \uc0ac\uc6a9\uc790\uc640 \ub300\ud654\ud558\uae30`_\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}