

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Transfer Learning tutorial &mdash; PyTorch Tutorials 0.3.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  
    <link rel="stylesheet" href="../_static/css/pytorch_theme.css" type="text/css" />
  
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="PyTorch Tutorials 0.3.1 documentation" href="../index.html"/>
        <link rel="next" title="Data Loading and Processing Tutorial" href="data_loading_tutorial.html"/>
        <link rel="prev" title="PyTorch: Control Flow + Weight Sharing" href="examples_nn/dynamic_net.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> PyTorch Tutorials
          

          
            
            <img src="../_static/pytorch-logo-dark.svg" class="logo" />
          
          </a>

          
            
            
              <div class="version">
                0.3.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Beginner Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="deep_learning_60min_blitz.html">PyTorch로 딥러닝하기: 60분만에 끝장내기</a><ul>
<li class="toctree-l2"><a class="reference internal" href="blitz/tensor_tutorial.html">PyTorch가 무엇인가요?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="blitz/tensor_tutorial.html#id1">시작하기</a><ul>
<li class="toctree-l4"><a class="reference internal" href="blitz/tensor_tutorial.html#tensors">Tensors</a></li>
<li class="toctree-l4"><a class="reference internal" href="blitz/tensor_tutorial.html#operations">연산(Operations)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="blitz/tensor_tutorial.html#numpy-bridge">NumPy 변환(Bridge)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="blitz/tensor_tutorial.html#torch-tensor-numpy">Torch Tensor를 NumPy 배열로 변환하기</a></li>
<li class="toctree-l4"><a class="reference internal" href="blitz/tensor_tutorial.html#numpy-torch-tensor">NumPy 배열을 Torch Tensor로 변환하기</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="blitz/tensor_tutorial.html#cuda-tensors">CUDA Tensors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="blitz/autograd_tutorial.html">Autograd: 자동 미분</a><ul>
<li class="toctree-l3"><a class="reference internal" href="blitz/autograd_tutorial.html#variable">변수(Variable)</a></li>
<li class="toctree-l3"><a class="reference internal" href="blitz/autograd_tutorial.html#gradient">변화도(Gradient)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="blitz/neural_networks_tutorial.html">신경망(Neural Networks)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="blitz/neural_networks_tutorial.html#id1">신경망 정의하기</a></li>
<li class="toctree-l3"><a class="reference internal" href="blitz/neural_networks_tutorial.html#loss-function">손실 함수 (Loss Function)</a></li>
<li class="toctree-l3"><a class="reference internal" href="blitz/neural_networks_tutorial.html#backprop">역전파(Backprop)</a></li>
<li class="toctree-l3"><a class="reference internal" href="blitz/neural_networks_tutorial.html#id4">가중치 갱신</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="blitz/cifar10_tutorial.html">분류기(Classifier) 학습하기</a><ul>
<li class="toctree-l3"><a class="reference internal" href="blitz/cifar10_tutorial.html#id1">데이터는 어떻게 하나요?</a></li>
<li class="toctree-l3"><a class="reference internal" href="blitz/cifar10_tutorial.html#id2">이미지 분류기 학습하기</a><ul>
<li class="toctree-l4"><a class="reference internal" href="blitz/cifar10_tutorial.html#cifar10">1. CIFAR10를 불러오고 정규화하기</a></li>
<li class="toctree-l4"><a class="reference internal" href="blitz/cifar10_tutorial.html#convolution-neural-network">2. 합성곱 신경망(Convolution Neural Network) 정의하기</a></li>
<li class="toctree-l4"><a class="reference internal" href="blitz/cifar10_tutorial.html#optimizer">3. 손실 함수와 Optimizer 정의하기</a></li>
<li class="toctree-l4"><a class="reference internal" href="blitz/cifar10_tutorial.html#id3">4. 신경망 학습하기</a></li>
<li class="toctree-l4"><a class="reference internal" href="blitz/cifar10_tutorial.html#id4">5. 시험용 데이터로 신경망 검사하기</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="blitz/cifar10_tutorial.html#gpu">GPU에서 학습하기</a></li>
<li class="toctree-l3"><a class="reference internal" href="blitz/cifar10_tutorial.html#id5">여러개의 GPU에서 학습하기</a></li>
<li class="toctree-l3"><a class="reference internal" href="blitz/cifar10_tutorial.html#id6">이제 뭘 해볼까요?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="blitz/data_parallel_tutorial.html">Optional: Data Parallelism</a><ul>
<li class="toctree-l3"><a class="reference internal" href="blitz/data_parallel_tutorial.html#imports-and-parameters">Imports and parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="blitz/data_parallel_tutorial.html#dummy-dataset">Dummy DataSet</a></li>
<li class="toctree-l3"><a class="reference internal" href="blitz/data_parallel_tutorial.html#simple-model">Simple Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="blitz/data_parallel_tutorial.html#create-model-and-dataparallel">Create Model and DataParallel</a></li>
<li class="toctree-l3"><a class="reference internal" href="blitz/data_parallel_tutorial.html#run-the-model">Run the Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="blitz/data_parallel_tutorial.html#results">Results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="blitz/data_parallel_tutorial.html#gpus">2 GPUs</a></li>
<li class="toctree-l4"><a class="reference internal" href="blitz/data_parallel_tutorial.html#id1">3 GPUs</a></li>
<li class="toctree-l4"><a class="reference internal" href="blitz/data_parallel_tutorial.html#id2">8 GPUs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="blitz/data_parallel_tutorial.html#summary">Summary</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="former_torchies_tutorial.html">Torch 사용자를 위한 PyTorch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="former_torchies/tensor_tutorial.html">Tensors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/tensor_tutorial.html#in-place-out-of-place">In-place / Out-of-place</a></li>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/tensor_tutorial.html#id1">0-인덱스</a></li>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/tensor_tutorial.html#camel-case">카멜표기법(Camel Case) 없음</a></li>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/tensor_tutorial.html#numpy-bridge">NumPy 변환(Bridge)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="former_torchies/tensor_tutorial.html#torch-tensor-numpy">Torch Tensor를 NumPy 배열로 변환하기</a></li>
<li class="toctree-l4"><a class="reference internal" href="former_torchies/tensor_tutorial.html#numpy-torch-tensor">NumPy 배열을 Torch Tensor로 변환하기</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/tensor_tutorial.html#cuda-tensors">CUDA Tensors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="former_torchies/autograd_tutorial.html">Autograd</a><ul>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/autograd_tutorial.html#variable">변수(Variable)</a></li>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/autograd_tutorial.html#gradient">변화도(Gradient)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="former_torchies/nn_tutorial.html">nn 패키지</a><ul>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/nn_tutorial.html#convnet">예제1: 합성곱 신경망(ConvNet)</a></li>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/nn_tutorial.html#hook">순방향/역방향 함수 훅(Hook)</a></li>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/nn_tutorial.html#recurrent-nets">예제2: 순환 신경망(Recurrent Nets)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="former_torchies/parallelism_tutorial.html">Multi-GPU examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/parallelism_tutorial.html#dataparallel">DataParallel</a></li>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/parallelism_tutorial.html#part-of-the-model-on-cpu-and-part-on-the-gpu">Part of the model on CPU and part on the GPU</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pytorch_with_examples.html">예제로 배우는 PyTorch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="pytorch_with_examples.html#tensor">Tensor</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#numpy">준비 운동: NumPy</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#pytorch-tensor">PyTorch: Tensor</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pytorch_with_examples.html#autograd">Autograd</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#pytorch-variables-autograd">PyTorch: Variables과 autograd</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#pytorch-autograd">PyTorch: 새 autograd 함수 정의하기</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#tensorflow-static-graph">TensorFlow: 정적 그래프(Static Graph)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pytorch_with_examples.html#nn-module"><cite>nn</cite> module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#pytorch-nn">PyTorch: nn</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#pytorch-optim">PyTorch: optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#pytorch-custom-nn-modules">PyTorch: Custom nn Modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#pytorch-control-flow-weight-sharing">PyTorch: Control Flow + Weight Sharing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pytorch_with_examples.html#examples">Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#tensors">Tensors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples_tensor/two_layer_net_numpy.html">준비 운동: NumPy</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples_tensor/two_layer_net_tensor.html">PyTorch: Tensor</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#id3">Autograd</a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples_autograd/two_layer_net_autograd.html">PyTorch: Variable과 autograd</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples_autograd/two_layer_net_custom_function.html">PyTorch: 새 autograd 함수 정의하기</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples_autograd/tf_two_layer_net.html">TensorFlow: 정적 그래프(Static Graph)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#id4"><cite>nn</cite> module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples_nn/two_layer_net_nn.html">PyTorch: nn</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples_nn/two_layer_net_optim.html">PyTorch: optim</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples_nn/two_layer_net_module.html">PyTorch: Custom nn Modules</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples_nn/dynamic_net.html">PyTorch: Control Flow + Weight Sharing</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Transfer Learning tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#load-data">Load Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#visualize-a-few-images">Visualize a few images</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#training-the-model">Training the model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#visualizing-the-model-predictions">Visualizing the model predictions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#finetuning-the-convnet">Finetuning the convnet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#train-and-evaluate">Train and evaluate</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#convnet-as-fixed-feature-extractor">ConvNet as fixed feature extractor</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">Train and evaluate</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="data_loading_tutorial.html">Data Loading and Processing Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="data_loading_tutorial.html#dataset-class">Dataset class</a></li>
<li class="toctree-l2"><a class="reference internal" href="data_loading_tutorial.html#transforms">Transforms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="data_loading_tutorial.html#compose-transforms">Compose transforms</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="data_loading_tutorial.html#iterating-through-the-dataset">Iterating through the dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="data_loading_tutorial.html#afterword-torchvision">Afterword: torchvision</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="deep_learning_nlp_tutorial.html">Deep Learning for NLP with Pytorch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nlp/pytorch_tutorial.html">Introduction to PyTorch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nlp/pytorch_tutorial.html#introduction-to-torch-s-tensor-library">Introduction to Torch’s tensor library</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nlp/pytorch_tutorial.html#creating-tensors">Creating Tensors</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp/pytorch_tutorial.html#operations-with-tensors">Operations with Tensors</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp/pytorch_tutorial.html#reshaping-tensors">Reshaping Tensors</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="nlp/pytorch_tutorial.html#computation-graphs-and-automatic-differentiation">Computation Graphs and Automatic Differentiation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nlp/deep_learning_tutorial.html">Deep Learning with PyTorch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nlp/deep_learning_tutorial.html#deep-learning-building-blocks-affine-maps-non-linearities-and-objectives">Deep Learning Building Blocks: Affine maps, non-linearities and objectives</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nlp/deep_learning_tutorial.html#affine-maps">Affine Maps</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp/deep_learning_tutorial.html#non-linearities">Non-Linearities</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp/deep_learning_tutorial.html#softmax-and-probabilities">Softmax and Probabilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp/deep_learning_tutorial.html#objective-functions">Objective Functions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="nlp/deep_learning_tutorial.html#optimization-and-training">Optimization and Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="nlp/deep_learning_tutorial.html#creating-network-components-in-pytorch">Creating Network Components in Pytorch</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nlp/deep_learning_tutorial.html#example-logistic-regression-bag-of-words-classifier">Example: Logistic Regression Bag-of-Words classifier</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nlp/word_embeddings_tutorial.html">Word Embeddings: Encoding Lexical Semantics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nlp/word_embeddings_tutorial.html#getting-dense-word-embeddings">Getting Dense Word Embeddings</a></li>
<li class="toctree-l3"><a class="reference internal" href="nlp/word_embeddings_tutorial.html#word-embeddings-in-pytorch">Word Embeddings in Pytorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="nlp/word_embeddings_tutorial.html#an-example-n-gram-language-modeling">An Example: N-Gram Language Modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="nlp/word_embeddings_tutorial.html#exercise-computing-word-embeddings-continuous-bag-of-words">Exercise: Computing Word Embeddings: Continuous Bag-of-Words</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nlp/sequence_models_tutorial.html">Sequence Models and Long-Short Term Memory Networks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nlp/sequence_models_tutorial.html#lstm-s-in-pytorch">LSTM’s in Pytorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="nlp/sequence_models_tutorial.html#example-an-lstm-for-part-of-speech-tagging">Example: An LSTM for Part-of-Speech Tagging</a></li>
<li class="toctree-l3"><a class="reference internal" href="nlp/sequence_models_tutorial.html#exercise-augmenting-the-lstm-part-of-speech-tagger-with-character-level-features">Exercise: Augmenting the LSTM part-of-speech tagger with character-level features</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nlp/advanced_tutorial.html">Advanced: Making Dynamic Decisions and the Bi-LSTM CRF</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nlp/advanced_tutorial.html#dynamic-versus-static-deep-learning-toolkits">Dynamic versus Static Deep Learning Toolkits</a></li>
<li class="toctree-l3"><a class="reference internal" href="nlp/advanced_tutorial.html#bi-lstm-conditional-random-field-discussion">Bi-LSTM Conditional Random Field Discussion</a></li>
<li class="toctree-l3"><a class="reference internal" href="nlp/advanced_tutorial.html#implementation-notes">Implementation Notes</a></li>
<li class="toctree-l3"><a class="reference internal" href="nlp/advanced_tutorial.html#exercise-a-new-loss-function-for-discriminative-tagging">Exercise: A new loss function for discriminative tagging</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Intermediate Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">Classifying Names with a Character-Level RNN</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#preparing-the-data">Preparing the Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#turning-names-into-tensors">Turning Names into Tensors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#creating-the-network">Creating the Network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#training">Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#preparing-for-training">Preparing for Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#training-the-network">Training the Network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#plotting-the-results">Plotting the Results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#evaluating-the-results">Evaluating the Results</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#running-on-user-input">Running on User Input</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#exercises">Exercises</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">Generating Names with a Character-Level RNN</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#preparing-the-data">Preparing the Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#creating-the-network">Creating the Network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#training">Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#preparing-for-training">Preparing for Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#training-the-network">Training the Network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#plotting-the-losses">Plotting the Losses</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#sampling-the-network">Sampling the Network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#exercises">Exercises</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">Translation with a Sequence to Sequence Network and Attention</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#loading-data-files">Loading data files</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#the-seq2seq-model">The Seq2Seq Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#the-encoder">The Encoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#the-decoder">The Decoder</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#simple-decoder">Simple Decoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#attention-decoder">Attention Decoder</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#training">Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#preparing-training-data">Preparing Training Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#training-the-model">Training the Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#plotting-results">Plotting results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#evaluation">Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#training-and-evaluating">Training and Evaluating</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#visualizing-attention">Visualizing Attention</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#exercises">Exercises</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">Reinforcement Learning (DQN) tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#replay-memory">Replay Memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#dqn-algorithm">DQN algorithm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#q-network">Q-network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#input-extraction">Input extraction</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#training">Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#hyperparameters-and-utilities">Hyperparameters and utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#training-loop">Training loop</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_tuto.html">파이토치로 분산 어플리케이션 개발하기</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/dist_tuto.html#setup">Setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/dist_tuto.html#point-to-point-communication">Point-to-Point Communication</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/dist_tuto.html#collective-communication">Collective Communication</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/dist_tuto.html#distributed-training">Distributed Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/dist_tuto.html#our-own-ring-allreduce">Our Own Ring-Allreduce</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/dist_tuto.html#advanced-topics">Advanced Topics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/dist_tuto.html#communication-backends">Communication Backends</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/dist_tuto.html#initialization-methods">Initialization Methods</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html">Spatial Transformer Networks Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html#loading-the-data">Loading the data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html#depicting-spatial-transformer-networks">Depicting spatial transformer networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html#training-the-model">Training the model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html#visualizing-the-stn-results">Visualizing the STN results</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Advanced Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced/neural_style_tutorial.html">Neural Transfer with PyTorch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../advanced/neural_style_tutorial.html#introduction">Introduction</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#neural-what">Neural what?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#how-does-it-work">How does it work?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../advanced/neural_style_tutorial.html#ok-how-does-it-work">OK. How does it work?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../advanced/neural_style_tutorial.html#pytorch-implementation">PyTorch implementation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#packages">Packages</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#cuda">Cuda</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#load-images">Load images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#display-images">Display images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#content-loss">Content loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#style-loss">Style loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#load-the-neural-network">Load the neural network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#input-image">Input image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#gradient-descent">Gradient descent</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/numpy_extensions_tutorial.html">Creating extensions using numpy and scipy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../advanced/numpy_extensions_tutorial.html#parameter-less-example">Parameter-less example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advanced/numpy_extensions_tutorial.html#parametrized-example">Parametrized example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/super_resolution_with_caffe2.html">Transfering a model from PyTorch to Caffe2 and Mobile using ONNX</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../advanced/super_resolution_with_caffe2.html#transfering-srresnet-using-onnx">Transfering SRResNet using ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advanced/super_resolution_with_caffe2.html#running-the-model-on-mobile-devices">Running the model on mobile devices</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/c_extension.html">C 언어로 PyTorch 확장 기능(custom extension) 만들기</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../advanced/c_extension.html#c">1단계. C 코드 준비하기</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advanced/c_extension.html#python">2단계. Python에서 불러오기</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">PyTorch Tutorials</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Transfer Learning tutorial</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/beginner/transfer_learning_tutorial.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="transfer-learning-tutorial">
<span id="sphx-glr-beginner-transfer-learning-tutorial-py"></span><h1>Transfer Learning tutorial<a class="headerlink" href="#transfer-learning-tutorial" title="Permalink to this headline">¶</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="https://chsasank.github.io">Sasank Chilamkurthy</a></p>
<p>In this tutorial, you will learn how to train your network using
transfer learning. You can read more about the transfer learning at <a class="reference external" href="http://cs231n.github.io/transfer-learning/">cs231n
notes</a></p>
<p>Quoting these notes,</p>
<blockquote>
<div>In practice, very few people train an entire Convolutional Network
from scratch (with random initialization), because it is relatively
rare to have a dataset of sufficient size. Instead, it is common to
pretrain a ConvNet on a very large dataset (e.g. ImageNet, which
contains 1.2 million images with 1000 categories), and then use the
ConvNet either as an initialization or a fixed feature extractor for
the task of interest.</div></blockquote>
<p>These two major transfer learning scenarios look as follows:</p>
<ul class="simple">
<li><strong>Finetuning the convnet</strong>: Instead of random initializaion, we
initialize the network with a pretrained network, like the one that is
trained on imagenet 1000 dataset. Rest of the training looks as
usual.</li>
<li><strong>ConvNet as fixed feature extractor</strong>: Here, we will freeze the weights
for all of the network except that of the final fully connected
layer. This last fully connected layer is replaced with a new one
with random weights and only this layer is trained.</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># License: BSD</span>
<span class="c1"># Author: Sasank Chilamkurthy</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">division</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="kn">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">lr_scheduler</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">copy</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>   <span class="c1"># interactive mode</span>
</pre></div>
</div>
<div class="section" id="load-data">
<h2>Load Data<a class="headerlink" href="#load-data" title="Permalink to this headline">¶</a></h2>
<p>We will use torchvision and torch.utils.data packages for loading the
data.</p>
<p>The problem we’re going to solve today is to train a model to classify
<strong>ants</strong> and <strong>bees</strong>. We have about 120 training images each for ants and bees.
There are 75 validation images for each class. Usually, this is a very
small dataset to generalize upon, if trained from scratch. Since we
are using transfer learning, we should be able to generalize reasonably
well.</p>
<p>This dataset is a very small subset of imagenet.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Download the data from
<a class="reference external" href="https://download.pytorch.org/tutorial/hymenoptera_data.zip">here</a>
and extract it to the current directory.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Data augmentation and normalization for training</span>
<span class="c1"># Just normalization for validation</span>
<span class="n">data_transforms</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="p">]),</span>
    <span class="s1">&#39;val&#39;</span><span class="p">:</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="p">]),</span>
<span class="p">}</span>

<span class="n">data_dir</span> <span class="o">=</span> <span class="s1">&#39;hymenoptera_data&#39;</span>
<span class="n">image_datasets</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span>
                                          <span class="n">data_transforms</span><span class="p">[</span><span class="n">x</span><span class="p">])</span>
                  <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]}</span>
<span class="n">dataloaders</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">image_datasets</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                                             <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
              <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]}</span>
<span class="n">dataset_sizes</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">image_datasets</span><span class="p">[</span><span class="n">x</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]}</span>
<span class="n">class_names</span> <span class="o">=</span> <span class="n">image_datasets</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">classes</span>

<span class="n">use_gpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
</pre></div>
</div>
<div class="section" id="visualize-a-few-images">
<h3>Visualize a few images<a class="headerlink" href="#visualize-a-few-images" title="Permalink to this headline">¶</a></h3>
<p>Let’s visualize a few training images so as to understand the data
augmentations.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">imshow</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Imshow for Tensor.&quot;&quot;&quot;</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">])</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">std</span> <span class="o">*</span> <span class="n">inp</span> <span class="o">+</span> <span class="n">mean</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">pause</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span>  <span class="c1"># pause a bit so that plots are updated</span>


<span class="c1"># Get a batch of training data</span>
<span class="n">inputs</span><span class="p">,</span> <span class="n">classes</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloaders</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]))</span>

<span class="c1"># Make a grid from batch</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

<span class="n">imshow</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="n">class_names</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">classes</span><span class="p">])</span>
</pre></div>
</div>
<img alt="../_images/sphx_glr_transfer_learning_tutorial_001.png" class="align-center" src="../_images/sphx_glr_transfer_learning_tutorial_001.png" />
</div>
</div>
<div class="section" id="training-the-model">
<h2>Training the model<a class="headerlink" href="#training-the-model" title="Permalink to this headline">¶</a></h2>
<p>Now, let’s write a general function to train a model. Here, we will
illustrate:</p>
<ul class="simple">
<li>Scheduling the learning rate</li>
<li>Saving the best model</li>
</ul>
<p>In the following, parameter <code class="docutils literal notranslate"><span class="pre">scheduler</span></code> is an LR scheduler object from
<code class="docutils literal notranslate"><span class="pre">torch.optim.lr_scheduler</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">):</span>
    <span class="n">since</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="n">best_model_wts</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
    <span class="n">best_acc</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Epoch {}/{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>

        <span class="c1"># Each epoch has a training and validation phase</span>
        <span class="k">for</span> <span class="n">phase</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
                <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>  <span class="c1"># Set model to training mode</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>  <span class="c1"># Set model to evaluate mode</span>

            <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">running_corrects</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># Iterate over data.</span>
            <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataloaders</span><span class="p">[</span><span class="n">phase</span><span class="p">]:</span>
                <span class="c1"># get the inputs</span>
                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>

                <span class="c1"># wrap them in Variable</span>
                <span class="k">if</span> <span class="n">use_gpu</span><span class="p">:</span>
                    <span class="n">inputs</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
                    <span class="n">labels</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">Variable</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

                <span class="c1"># zero the parameter gradients</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="c1"># forward</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

                <span class="c1"># backward + optimize only if in training phase</span>
                <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
                    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="c1"># statistics</span>
                <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">running_corrects</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">labels</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="n">running_loss</span> <span class="o">/</span> <span class="n">dataset_sizes</span><span class="p">[</span><span class="n">phase</span><span class="p">]</span>
            <span class="n">epoch_acc</span> <span class="o">=</span> <span class="n">running_corrects</span> <span class="o">/</span> <span class="n">dataset_sizes</span><span class="p">[</span><span class="n">phase</span><span class="p">]</span>

            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;{} Loss: {:.4f} Acc: {:.4f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">phase</span><span class="p">,</span> <span class="n">epoch_loss</span><span class="p">,</span> <span class="n">epoch_acc</span><span class="p">))</span>

            <span class="c1"># deep copy the model</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;val&#39;</span> <span class="ow">and</span> <span class="n">epoch_acc</span> <span class="o">&gt;</span> <span class="n">best_acc</span><span class="p">:</span>
                <span class="n">best_acc</span> <span class="o">=</span> <span class="n">epoch_acc</span>
                <span class="n">best_model_wts</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>

        <span class="k">print</span><span class="p">()</span>

    <span class="n">time_elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">since</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Training complete in {:.0f}m {:.0f}s&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">time_elapsed</span> <span class="o">//</span> <span class="mi">60</span><span class="p">,</span> <span class="n">time_elapsed</span> <span class="o">%</span> <span class="mi">60</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Best val Acc: {:4f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_acc</span><span class="p">))</span>

    <span class="c1"># load best model weights</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">best_model_wts</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<div class="section" id="visualizing-the-model-predictions">
<h3>Visualizing the model predictions<a class="headerlink" href="#visualizing-the-model-predictions" title="Permalink to this headline">¶</a></h3>
<p>Generic function to display predictions for a few images</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">visualize_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_images</span><span class="o">=</span><span class="mi">6</span><span class="p">):</span>
    <span class="n">was_training</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">training</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">images_so_far</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloaders</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">]):</span>
        <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
        <span class="k">if</span> <span class="n">use_gpu</span><span class="p">:</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">cuda</span><span class="p">()),</span> <span class="n">Variable</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">Variable</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">images_so_far</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">num_images</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">images_so_far</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;predicted: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">class_names</span><span class="p">[</span><span class="n">preds</span><span class="p">[</span><span class="n">j</span><span class="p">]]))</span>
            <span class="n">imshow</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>

            <span class="k">if</span> <span class="n">images_so_far</span> <span class="o">==</span> <span class="n">num_images</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">was_training</span><span class="p">)</span>
                <span class="k">return</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">was_training</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="finetuning-the-convnet">
<h2>Finetuning the convnet<a class="headerlink" href="#finetuning-the-convnet" title="Permalink to this headline">¶</a></h2>
<p>Load a pretrained model and reset final fully connected layer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_ft</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">num_ftrs</span> <span class="o">=</span> <span class="n">model_ft</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span>
<span class="n">model_ft</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_ftrs</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="k">if</span> <span class="n">use_gpu</span><span class="p">:</span>
    <span class="n">model_ft</span> <span class="o">=</span> <span class="n">model_ft</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Observe that all parameters are being optimized</span>
<span class="n">optimizer_ft</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model_ft</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="c1"># Decay LR by a factor of 0.1 every 7 epochs</span>
<span class="n">exp_lr_scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer_ft</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="train-and-evaluate">
<h3>Train and evaluate<a class="headerlink" href="#train-and-evaluate" title="Permalink to this headline">¶</a></h3>
<p>It should take around 15-25 min on CPU. On GPU though, it takes less than a
minute.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_ft</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model_ft</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer_ft</span><span class="p">,</span> <span class="n">exp_lr_scheduler</span><span class="p">,</span>
                       <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span> <span class="mi">0</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.5476</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7213</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2652</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8824</span>

<span class="n">Epoch</span> <span class="mi">1</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.8387</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7213</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3071</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8824</span>

<span class="n">Epoch</span> <span class="mi">2</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.4902</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7828</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2093</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9281</span>

<span class="n">Epoch</span> <span class="mi">3</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.5741</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7705</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1520</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9608</span>

<span class="n">Epoch</span> <span class="mi">4</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.6082</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7910</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.4943</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8039</span>

<span class="n">Epoch</span> <span class="mi">5</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.5905</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7869</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2621</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9346</span>

<span class="n">Epoch</span> <span class="mi">6</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3868</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8484</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2538</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9412</span>

<span class="n">Epoch</span> <span class="mi">7</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3687</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8689</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2500</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9216</span>

<span class="n">Epoch</span> <span class="mi">8</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.4076</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8402</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2726</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9216</span>

<span class="n">Epoch</span> <span class="mi">9</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3313</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8566</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2179</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9477</span>

<span class="n">Epoch</span> <span class="mi">10</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2705</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8893</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2540</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9150</span>

<span class="n">Epoch</span> <span class="mi">11</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3414</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8566</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2476</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9281</span>

<span class="n">Epoch</span> <span class="mi">12</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2630</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9057</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2305</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9346</span>

<span class="n">Epoch</span> <span class="mi">13</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2412</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9016</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2131</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9281</span>

<span class="n">Epoch</span> <span class="mi">14</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2869</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8811</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2278</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9216</span>

<span class="n">Epoch</span> <span class="mi">15</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2988</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8811</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2373</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9216</span>

<span class="n">Epoch</span> <span class="mi">16</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3754</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8402</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2721</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9085</span>

<span class="n">Epoch</span> <span class="mi">17</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2624</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8689</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2550</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9150</span>

<span class="n">Epoch</span> <span class="mi">18</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1964</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9180</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2399</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9216</span>

<span class="n">Epoch</span> <span class="mi">19</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2853</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8770</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2289</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9281</span>

<span class="n">Epoch</span> <span class="mi">20</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2650</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8934</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2337</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9346</span>

<span class="n">Epoch</span> <span class="mi">21</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2267</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8975</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2433</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9150</span>

<span class="n">Epoch</span> <span class="mi">22</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2796</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8893</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2280</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9346</span>

<span class="n">Epoch</span> <span class="mi">23</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2596</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8811</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2194</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9477</span>

<span class="n">Epoch</span> <span class="mi">24</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2886</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8730</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2193</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9412</span>

<span class="n">Training</span> <span class="n">complete</span> <span class="ow">in</span> <span class="mi">0</span><span class="n">m</span> <span class="mi">57</span><span class="n">s</span>
<span class="n">Best</span> <span class="n">val</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.960784</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">visualize_model</span><span class="p">(</span><span class="n">model_ft</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/sphx_glr_transfer_learning_tutorial_002.png" class="align-center" src="../_images/sphx_glr_transfer_learning_tutorial_002.png" />
</div>
</div>
<div class="section" id="convnet-as-fixed-feature-extractor">
<h2>ConvNet as fixed feature extractor<a class="headerlink" href="#convnet-as-fixed-feature-extractor" title="Permalink to this headline">¶</a></h2>
<p>Here, we need to freeze all the network except the final layer. We need
to set <code class="docutils literal notranslate"><span class="pre">requires_grad</span> <span class="pre">==</span> <span class="pre">False</span></code> to freeze the parameters so that the
gradients are not computed in <code class="docutils literal notranslate"><span class="pre">backward()</span></code>.</p>
<p>You can read more about this in the documentation
<a class="reference external" href="http://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward">here</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_conv</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model_conv</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">False</span>

<span class="c1"># Parameters of newly constructed modules have requires_grad=True by default</span>
<span class="n">num_ftrs</span> <span class="o">=</span> <span class="n">model_conv</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span>
<span class="n">model_conv</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_ftrs</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="k">if</span> <span class="n">use_gpu</span><span class="p">:</span>
    <span class="n">model_conv</span> <span class="o">=</span> <span class="n">model_conv</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Observe that only parameters of final layer are being optimized as</span>
<span class="c1"># opoosed to before.</span>
<span class="n">optimizer_conv</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model_conv</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="c1"># Decay LR by a factor of 0.1 every 7 epochs</span>
<span class="n">exp_lr_scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer_conv</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="id1">
<h3>Train and evaluate<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>On CPU this will take about half the time compared to previous scenario.
This is expected as gradients don’t need to be computed for most of the
network. However, forward does need to be computed.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_conv</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model_conv</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer_conv</span><span class="p">,</span>
                         <span class="n">exp_lr_scheduler</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span> <span class="mi">0</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.5606</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.6926</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2299</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9412</span>

<span class="n">Epoch</span> <span class="mi">1</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.6001</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.6844</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1683</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9673</span>

<span class="n">Epoch</span> <span class="mi">2</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.6136</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7172</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2625</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9085</span>

<span class="n">Epoch</span> <span class="mi">3</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.4327</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8156</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2455</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9085</span>

<span class="n">Epoch</span> <span class="mi">4</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.4287</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8197</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2053</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9477</span>

<span class="n">Epoch</span> <span class="mi">5</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.6528</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7500</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1952</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9608</span>

<span class="n">Epoch</span> <span class="mi">6</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.5463</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7951</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1990</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9608</span>

<span class="n">Epoch</span> <span class="mi">7</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3502</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8607</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1832</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9608</span>

<span class="n">Epoch</span> <span class="mi">8</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3753</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8238</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1897</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9608</span>

<span class="n">Epoch</span> <span class="mi">9</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3605</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8443</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2004</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9608</span>

<span class="n">Epoch</span> <span class="mi">10</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3462</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8689</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2307</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9346</span>

<span class="n">Epoch</span> <span class="mi">11</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.4127</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8279</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1971</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9542</span>

<span class="n">Epoch</span> <span class="mi">12</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3644</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8566</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1919</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9608</span>

<span class="n">Epoch</span> <span class="mi">13</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3619</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8361</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1973</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9542</span>

<span class="n">Epoch</span> <span class="mi">14</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2770</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8730</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1838</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9608</span>

<span class="n">Epoch</span> <span class="mi">15</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3772</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8484</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1883</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9608</span>

<span class="n">Epoch</span> <span class="mi">16</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3584</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8361</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1817</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9608</span>

<span class="n">Epoch</span> <span class="mi">17</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3090</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8852</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1927</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9477</span>

<span class="n">Epoch</span> <span class="mi">18</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3483</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8607</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1888</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9542</span>

<span class="n">Epoch</span> <span class="mi">19</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3395</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8770</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1867</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9412</span>

<span class="n">Epoch</span> <span class="mi">20</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2928</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8566</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1874</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9542</span>

<span class="n">Epoch</span> <span class="mi">21</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3037</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8648</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1738</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9608</span>

<span class="n">Epoch</span> <span class="mi">22</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3586</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8607</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1903</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9542</span>

<span class="n">Epoch</span> <span class="mi">23</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3503</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8484</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1845</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9608</span>

<span class="n">Epoch</span> <span class="mi">24</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2155</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9098</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1870</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9608</span>

<span class="n">Training</span> <span class="n">complete</span> <span class="ow">in</span> <span class="mi">0</span><span class="n">m</span> <span class="mi">37</span><span class="n">s</span>
<span class="n">Best</span> <span class="n">val</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.967320</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">visualize_model</span><span class="p">(</span><span class="n">model_conv</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ioff</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/sphx_glr_transfer_learning_tutorial_003.png" class="align-center" src="../_images/sphx_glr_transfer_learning_tutorial_003.png" />
<p><strong>Total running time of the script:</strong> ( 1 minutes  40.449 seconds)</p>
<div class="sphx-glr-footer docutils container">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../_downloads/transfer_learning_tutorial.py" download=""><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">transfer_learning_tutorial.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../_downloads/transfer_learning_tutorial.ipynb" download=""><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">transfer_learning_tutorial.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="data_loading_tutorial.html" class="btn btn-neutral float-right" title="Data Loading and Processing Tutorial" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="examples_nn/dynamic_net.html" class="btn btn-neutral" title="PyTorch: Control Flow + Weight Sharing" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, PyTorch.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.3.1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-71919972-2', 'auto');
  ga('send', 'pageview');

</script>


</body>
</html>